#!/bin/bash
# A simple script

function run_fun {

    flock -n -x $1 -c "if python3 cron_jobs/data_insert/format_data.py -p $1 -f $(basename $(dirname $(dirname "$1"))) -s $(basename $(dirname "$1")); then rm $1; else mkdir -p $PDIR$(basename $(dirname "$1"))/ && mv $1 $PDIR$(basename $(dirname "$1"))/; fi"

    #if python3 cron_jobs/data_insert/format_data.py -p $1 -f $(basename $(dirname $(dirname "$1"))) -s $(basename $(dirname "$1")); then rm $1; else mkdir -p $PDIR$(basename $(dirname "$1"))/ && mv $1 $PDIR$(basename $(dirname "$1"))/; fi
    return 0
}

function test_fun {
    if python3 format_data.py -p $1 -f $(basename $(dirname $(dirname "$1"))) -s $(basename $(dirname "$1")) -l true; then rm $1; else mkdir -p $PDIR$(basename $(dirname "$1"))/ && mv $1 $PDIR$(basename $(dirname "$1"))/; fi
}

if [ "$2" == '--local' ] && [ "$1" != "" ]; then

    export -f test_fun
    export PDIR="package_probs/"

    generalslots=6
    totalslots=8
    maxsize=200000
    ns=5

    mkdir -p $PDIR
    #mkdir -p $DDIR
    #source bin/activate

    #get lock
    exec 100>lock.lock || exit 1
    flock -n -x 100 || exit 1

    echo "running local"
    while :;
    do
        currenttime=$(date +%R)
        if [[ "$currenttime" < "00:05" ]]; then
            wait
            break
        fi

        echo "-- Number of jobs: -- "
        jobs
        echo "---- JOBS DONE ----"

        # If we have more jobs running than general reserved slots, then only work on small files
        if [[ $(jobs -r -p | wc -l) -ge $generalslots ]]; then
            #echo "Finding file for restricted slot"
            f=$(find "$1" -name "*.gz" -type f -size -${maxsize}c | sort -t / -k $ns,$ns -nr | head -n 100 | (xargs -r python3 fuser.py) | grep -v ': ' | sed -e 's/:$//' | head -n 1)
        else
            #echo "Finding general file"
            f=$(find "$1" -name "*.gz" -type f | sort -t / -k $ns,$ns -nr | head -n 100 | (xargs -r python3 fuser.py) | grep -v ': ' | sed -e 's/:$//' | head -n 1)
        fi

        # If we got a filename to work on, then send it to the work function
        if [ -n "$f" ]; then
            echo "starting file"
            flock -n -x "$f" bash -c 'test_fun "$0"' $f &
        fi

        # if we have more jobs running than our total slots, then wait for one of them to finish
        if [[ $(jobs -r -p | wc -l) -ge $totalslots ]]; then
            wait -n;
        fi
        sleep 0.1
    done

elif [ "$1" != "" ]; then
    #export DATABASE_URL=postgresql://db_master:1234@localhost/angle_db
    ## get port and login from dokku

    ## import env
    set -o allexport; source /app/.env; set +o allexport


    export -f run_fun
    export PDIR="/app/uploads/package_probs/"
    #export LOCKS="/app/uploads/locks/"

    generalslots=6
    totalslots=8
    maxsize=200000
    ns=5

    mkdir -p $PDIR
    mkdir -p $LOCKS

    # get lock
    exec 100>/app/uploads/locks/data_insert.lock || exit 1
    flock -n -x 100 || exit 1

    while :;
    do
        currenttime=$(date +%R)
        if [[ "$currenttime" < "00:05" ]]; then
            wait
            break
        fi

        #find "$1" -name "*.gz" -type f | sort -t / -k 5,5 -nr | head -n 24 | xargs -n 1 -P 8 -I {} bash -c 'run_fun "$@"' _ {}
        #find "$1" -name "*.gz" -type f | xargs -n 1 -P 16 -I {} bash -c 'run_fun "$@"' _ {}

        # If we have more jobs running than general reserved slots, then only work on small files
        if [[ $(jobs -r -p | wc -l) -ge $generalslots ]]; then
            f=$(find "$1" -name "*.gz" -type f -size -${maxsize}c | sort -t / -k $ns,$ns -nr | head -n 100 | (xargs -r python3 cron_jobs/data_insert/fuser.py) | grep -v ': ' | sed -e 's/:$//' | head -n 1)
        else
            f=$(find "$1" -name "*.gz" -type f | sort -t / -k $ns,$ns -nr | head -n 100 | (xargs -r python3 cron_jobs/data_insert/fuser.py) | grep -v ': ' | sed -e 's/:$//' | head -n 1)
        fi
        # If we got a filename to work on, then send it to the work function
        if [ -n "$f" ]; then
            flock -n -x "$f" bash -c 'run_fun "$0"' $f &
        else
            sleep 1
        fi

        # if we have more jobs running than our total slots, then wait for one of them to finish
        if [[ $(jobs -r -p | wc -l) -ge $totalslots ]]; then wait -n; fi
        sleep 0.1
    done
else
    echo "first parameter needs to contain path to data"
    exit 1
fi
